# Sticky Sessions

Let's talk about sticky sessions,

also called session affinity

for your Elastic Load Balancer.

So it's possible to implement what's called stickiness

or sticky sessions,

and the idea is that the client

doing two requests to the load balancer

will have the same instance

in the backend to respond to the request.

So the idea is that for example,

you have the ALB with two EC2 instances,

and you have three clients.

If the client one makes a request

and it goes to the first EC2 instance,

that means that when it does a second request

to the load balancer,

it will go to the same instance.

Which is a different behavior

where usually the Application Load Balancer

will do a spread of all the requests

across all the EC2 instances.

Now for client two, if it goes to the ALB

and talks to the second instance,

then all the requests will go there.

And same for client three.

Okay?

So this can be enabled

for the Classic Load Balancer, Application Load Balancer

and the Network Load Balancer

And how it works, well there is a cookie

that is sent as part of the request

from the client's two load balancer.

And it has stickiness and it has an expiration date,

that means that when the cookie expires

then the client may be redirected to another EC2 instance.

Use case for this is to make sure

that the user is connected to the same backend instance,

in order not to lose his session data.

Which can take some important information

such as the login of the user, for example.

But if you enable stickiness,

it may bring imbalance to the load

over the backend EC2 instances,

in case some instances I have a very, very sticky user.

Okay.

Now to go a little bit deeper,

how about the cookie itself?

Well, there are two types of cookie

that you can have for sticky sessions.

The first one is application-based cookie,

and the second one is duration-based cookie.

So for application-based cookies,

well it's a custom cookie

that is generated by the target,

so by your application itself.

And you can include any custom attributes you want

by required by your application.

The cookie name must be specified individually

for each target group, okay?

And you must not use the following name,

so AWSALB, AWSALBAPP, OR AWSALBTG,

because they are already reserved

for used by the ALB itself.

Or it could be an application cookie,

and this time will be generated by the load balancer itself.

And the cookie name used by the ALB will be AWSALBAPP.

Okay?

Now the second type of cookies is duration-based cookie,

and it's a cookie generated by the load balancer.

And the name is AWSALB for the ALB,

and AWSELB for the CLB.

Okay?

And the idea is this one will have an expiry

based on a specific duration,

and the duration is generated

by the load balancer itself.

Okay?

Whereas before, well there

is an application-based cookie,

so the duration can be specified by the application itself.

So that's how it works, okay?

You don't need to remember exactly the name of the cookies

or the fact that you have custom and application,

but you remember there is application-based cookies

and duration-based cookies,

and they have a specific name,

and this will be coming into account

when we talk about CloudFront.

Okay?

So if I look at my load balancer right now,

and I open it in the new tab, as you can see

it goes between my three instances in my load balancer.

So that's perfect.

But now I'm going to enable sticky sessions.

So to do so, I'm going to go at the target group level,

open my target group,

and then Action.

And I will can edit the attributes of my target group.

And in the bottom I have Stickiness or sticky sessions.

And as we can see,

we have two types of stickiness available to us.

Okay?

We have the load balancer generated cookie,

which is a duration type of stickiness.

So I can say between one second and seven days.

Or I can have an application-based cookie,

between one second to seven days again,

but this time I need to specify the cookie name

that is sent by the app to the load balancer.

So it could be MYCUSTOMAPPCOOKIE.

And then this is what the load balancer

would be using to perform the stickiness.

Okay?

So that's it for stickiness.

As we can see,

if we just have a load balancer generated cookie

and we set the stickiness duration to be equal

to say one day,

and I will save this change.

So now let's have a look.

So I'm going to go and open the debugger as well

so we can have a look at the network

and see what happens.

So if we have a look at the network,

and then I refresh this page,

as we can see, I refresh it multiple times.

Okay?

You get access to the same instance.

So 7-176 is the one

that's coming back, back, and back, and back.

And now what's going to happen is

that when you look at the GET request made

to the load balancer,

and I'm very, very sorry for the font size here,

I don't think I can really increase it.

But if you go to Cookies, as you can see here,

there is a response cookie, okay?

That is saying that your cookie expires tomorrow.

Here is the path,

and here is the value of the cookie.

And then in the request cookie,

when the browser makes a request to the load balancer

it sends again the cookie it has right here.

And so because of the cookie being passed and sent,

this is how stickiness works.

Okay?

So just a little bit of a deeper dive

into how stickiness works.

But that's it for this lecture,

I hope you liked it.

And by the way, to access the web developer tools,

you click on Web Developer

and then Web Developer Tools.

And I just use a short shortcut for that.

And it's the same on Chrome and Firefox.

And then you go into Network,

and you get access to your information around your request.

Okay?

And finally, just go back to your target group

and then you edit the attributes itself,

and you can disable stickiness

to come back to normal behavior.

We should be good to go.

So that's it for this lecture, I hope you liked it.

And I will see you in the next lecture.

# Cross Zone Load Balancing

Now let's talk about cross zone balancing.

So let's take an example of a very imbalanced situation

but it will illustrate the point.

So we two availability zones

and the first one has a load balancer

with two EC2 instances.

And the second one also has a load balancer.

So a load balancer instance obviously,

with eight EC2 instances.

The Load balance serves instances are part

of the same more general load balancer.

So the client is accessing these load balancers.

And so with cross zone load balancing

each load balancer instance will distribute evenly

across all registered instances in all availability zones.

So the client itself is sending 50%

of the traffic to the first ALB instance

and 50% of traffic to the other ALB instance.

But each ALB is going to redirect the traffic

across all 10 EC2 instances

regardless of which availability zones they're in.

This is why it's called cross zone load balancing.

So if you take a look at the first

at the second ALB, sorry instance

it's going to send 10% of the traffic it receives, okay?

To all these instances because we have 10 instances.

So each of them gets 10% of the traffic.

And same story with the first ALB instance.

It's going to send also 10%

of traffic to all these instances.

So in this example with cross zone balancing

we are distributing the traffic evenly

across all EC2 instances.

And then maybe something you want to have or not, who knows

but at least this behavior is available to you.

The second behavior that's available

to you is to not have cross zone balancing.

So we take the same example

but without cross zone balancing.

The requests, the requests, sorry, are distributed

in the instances of the node of the elastic load balancer.

So in this example, what we have is that the client

sends 50% of the traffic to the first AZ and the 50%

of traffic to the second AZ, okay?

But the first ALB instance is going to send the traffic

to only the EC2 instances in its region.

So that means that each EC2 instance in this sorry ability

zone is going to get 25% of the traffic overall, okay?

So half and half.

And the one on the right hand side will again divide

up the traffic it receives into the EC2 instances

that are registered within its AZ.

So AZ2.

So we can see here without cross balancing

the traffic is contained within each AZ.

But if there are an imbalanced number of EC2 instances

in each AZ, then some EC2 instances of a specific AZ we'll

receive more traffic than others.

It's just an option to know about.

There's no right or wrong answer.

It depends on the use case, obviously.

So for the application balancer, by default

cross zone load balancing is going to be enabled

but you can disable it at the target group level and

there's going to be no charges

if your data goes across availability zones

because usually in AWS, if data goes

from one AZ to another one, you're going to pay some money.

But for the application balancer

because cross zone lowdown is enabled by default

you won't have any charges for inter AZ data.

Now, if you consider the network load balancer

and the gateway load balancer,

then cross zone load balancing is disabled by default.

And if you enable it

then you're going to pay some amount of money

because the data is going to go from one AZ to the next.

Finally, for the classic load balancer

it is disabled by default, and in case you enable it

you're not going to be charged for inter AZ data transfers.

Okay, so just for the sake of doing a hands on

I've created a workload balancer, an application balancer

and a gateway load balancer.

So let's first have a look at the network load balancer.

So if I scroll down and click on attributes, as you can see

cross zone low balancing is off

but I can edit this and turn this on.

And as you can see, I will enable cross zone balancing

and this may include some regional charges for your NLB.

So this is a similar setting for the gateway low balancer

because they have a similar behavior in that regard.

So for the attributes, again, cross zone

load balancing is off

but I can edit it and turn it on.

And this will imply data charges.

Now if you have a look at the application load balancer

it is a little bit different.

So if you go to attributes

you can see that cross zone load balancing is on by default.

And if I edit this and and scroll down, as you can see

I will show you in a second.

As you can see, the cross zone balancing is always on,

okay?

And this message

you can discard it because I think it's wrong.

But anyway, so cross zone load balancing

is always on for your ALB.

But if you go to your actual target group, so if I go

to my target group that has been created for this and I go

to attributes of the target group, we can actually do edit.

And for the cross zone load balancing here, we can

either inherit settings from the low balancer attributes

which is on by default or force on or off

and turn it off for that one specific target group.

And when it comes

to doing the demo for the classic load balancer,

I will not include it this time

because the classic load balancer is going away.

It is previous generation

and is going to be retired very soon.

So I don't think you will need to know

about it for the exam.

Okay, so let's see.

For this lecture, just make sure

if you wanted to follow along to delete the load balancers.

I hope you liked it and I will see you in the next lecture.


# SSL Certificates

Okay, so now let's talk about SSL

and TLS Certificates.

So this is a dumb down version of how this works.

This is obviously way more complicated

but I want to introduce you to the concepts

in case you don't know it.

And even if you do know SSL and TLS,

please watch this lecture.

I'm going to talk about SNI

and I'm going to talk about the integrations

with load balancers.

So bear with me please.

So an SSL certificate allows the traffic

between your clients and your load balancer

to be encrypted while in transit.

This is called in-flight encryption.

So that means the data as it goes through a network is going

to be encrypted and only going to be able to be decrypted

by the sender and the receiver.

So, SSL refers to Secure Sockets Layer

and it's used to encrypt transfer connections.

And TLS is the newer version of SSL

and it refers to Transport Layer Security.

But the thing is, nowadays,

TLS certificates are the one that are mainly used,

but people, including myself,

I will still refer this as SSL.

So I'm making a mistake,

but I'm making it on purpose, okay?

So it's better to say a TLS certificate

than SSL certificates,

but for many reasons, I'm still gonna say it's SSL

because it's easier to understand.

So public SSL certificates are issued

by Certificate Authorities,

and they include something like Comodo, Symantec, GoDaddy,

GlobalSign, Digicert, Letsencrypt, and so on.

And using this public SSL certificate attached

to our load balancer,

we're able to encrypt the connection

between the clients and the load balancer.

So whenever you go to a website,

for example google.com or anything, any other website,

and you have a lock or a green lock

that means that your traffic is encrypted.

And if traffic is not encrypted,

you'll have a red sign saying,

"Hey, traffic is not encrypted.

Don't put your credit card details.

Don't put your login information because it's not secure."

So the SSL certificates, they have an an expiration date

that you set and they must be renewed regularly

to make sure that they're authentic, okay?

So how does it work from a load balancer perspective?

So users connect over HTTPS,

and it's S because it's using SSL certificates

and it's encrypted.

It's secure,

and it connects over the public internet

to your load balancer.

And internally, your load balancer does something

called SSL certificate termination.

And in the backend, it can talk to your EC2 instance

using HTTP, so not encrypted,

but the traffic goes over your VPC,

which is private traffic network.

And that is somewhat secure.

So the load balancer will load an X.509 certificate,

which is called a SSL or TLS server certificate.

And you can manage these SSL certificates in AWS using ACM,

meaning AWS Certificate Manager.

So we're not going to view ACM in that lecture

but just to get an idea of what it is.

Now, you can also upload your own certificates

to ACM if you wanted to.

And when you set you an HTTPS listener,

you must specify a default certificate.

Then you can add an optional list of certs

to support multiple domains,

and clients can use something called SNI

or Server Name Indication

to specify the hostname they reach.

Now don't worry, I'm going to explain what SNI is

in details in the next slide

because it is really, really important for you

to understand what it means.

That means that, and you can also,

finally for HTTPS, set a specific security policy

if you wanted to support all their versions

of SSL and TLS, called also legacy clients.

Okay, so let's talk about SNI 'cause it is so important.

SNI solves a very important problem,

which is how do you load multiple SSL certificates

onto one web server in order for that web server

to serve multiple websites?

And there's a newer protocol

that now requires the client to indicate the hostname

of the target server in the initial SSL handshake.

So the client will say,

"I want to connect to this website."

And the server will know what certificate to load.

And so, this is a newer protocol and this is something new.

Not every client supports this.

So it only works when you use the application load balancer

and the network load balancer, so the newer generations,

or CloudFront.

And we'll see what CloudFront is later in this course.

And it does not work when you use the classic load balancer

because it is older generation.

So anytime you see multiple SSL certificates

onto your load balancer, think ALB or NLB.

So as a diagram, what does it look like?

We have our ALB here and we have two target groups.

The first one is www.mycorp.com,

and the second one is Domain1.example.com.

So the ALB will be routing to these target groups

based on some rules and the rules may be directly linked,

in this case to the hostname.

So the ALB will have two SSL certificates:

Domain1.example.com and www.mycorp.com,

which corresponds to the corresponding target groups.

Now the clients connects to our ALB and says,

"I would like www.mycorp.com",

and that is part of server name indication.

And the ALB says, "Okay, I've seen that you want mycorp.com.

Let me use the correct SSL certificates

to fill that request."

So it's going to take the right SSL certificates,

encrypt the traffic,

and then thanks to the routes,

it's going to know to redirect

to the correct target group, mycorp.com.

And obviously, if you have another client connecting

to your ALB for Domain1.example.com,

then you will be able

to pull the right SSL certificate again

and connect to the right target group.

So using SNI or server name indication,

you are able to have multiple target groups

for different websites using different SSL certificates.

Excellent.

So finally, what is supported for SSL certificates?

So classic load balancer is yes,

you can only support one SSL certificate.

And if you want multiple hostnames

with multiple SSL certificates,

the best way is to use multiple classic load balancer.

For ALB, the v2, you need to,

you can support multiple listeners

with multiple SSL certificates.

And that's the great part of it,

and it uses SNI to make it work.

And we just saw what it is.

And for the NLB or network load balancer,

it supports, again, multiple listeners

with multiple SSL certificates,

and it will use SNI again to make it work.

So let's have a look at how we can enable

SSL certificates on both the ALB and the NLB.

So if I look at the ALB,

I just have to add one listener, for example,

I will add a listener, and the protocol will be HTTPS

and the ports by default will be 443.

And then we can say, okay if the clients are using

the port 403 for HTTPS protocol,

then forward to a specific target group.

And then we can also have secure listener settings.

So we can say, we can actually set a SSL security policy

to see how to negotiate the certificates itself,

and this is based on if you need, for example,

previous compatibility with older version of SSL or TLS

and so on, so you can leave this as default

and then you need to say where this SSL

or TLS certificate is located

and so it can be in ACM, Amazon Certificate Manager,

but I currently don't have any,

so I won't see here one or from IAM,

but this is not recommended as domain method.

Or you can import it by just pasting the private key,

the body and the certificate chain here if need be

and then this will import the certificate itself

into ACM directly.

So it's a similar process for the network cloud balancer.

So if I go in the network balancer right here,

and have a look at the listeners,

I can add a listener of it being TLS,

and then we can forward to a demo target group right here

and then for security policy,

we can set whatever policy we want,

as well as choose where the certificate is from

so from SCM, IAM, or import, and finally we can set

an application layer protocol negotiation,

which I won't go over

but this is a pretty advanced setting for TLS.

So that's it, you've seen how to use SSL

or TLS certificates on your load balancers.

I hope you liked it and I will see you in the next lecture.

# Connection Draining

So now let's talk about a feature

that can come up in the exam,

which is called Connection Draining.

So it has two names, actually.

If you're using a Classic Load Balancer,

it is called Connection Draining,

but if you're using an Application Balancer

or a Network Load Balancer,

this is called a Deregistration Delay.

And the idea behind this concept is that

it will give some time for your instances

to complete the inflight request or the active request

while the instance is being deregistered

or marked unhealthy.

And once a connection is being drained,

so once an instance is being drained,

then the ELB will stop sending your request

to the EC2 instance that is being drained

while being deregistered.

So let's have a look at a diagram to understand better.

So we have three EC2 instances

and in one of them we'll set it in draining mode.

So the users that are already connected to that EC2 instance

are going to be given enough time,

which is the draining period, okay,

to complete their existing connection

and to complete their existing request.

And then once everything's done,

then all the connections will be shut down.

Now, if new users try to connect to our ELB,

our ELB is smart enough to know

that because our EC2 instance is in draining state,

then it will only establish new connections

with other EC2 instances, for example,

my second EC2 instance or my third EC2 instance.

Now you can parametrize

these Connection Draining parameters.

So you can set it anywhere between 1 to 3,600 seconds.

By default, it is 300 seconds, so five minutes,

and you can disable it altogether

if you set the value to zero,

which means that there's no draining happening.

Now, if you set it to low value, okay, this is good

if your requests are short, for example, if there were very,

very short requests for, let's say, less than one second,

well, it's a good idea to set

the draining connection parameter to maybe 30 seconds, okay,

because then this will allow your EC2 instance

to be drained really fast and then be taken offline,

maybe to be replaced or something like this.

If your request can be quite long, for example,

if you have uploads or long lived requests,

then you want to set it to something pretty high,

but the trade-off is that's your EC2 instance

is not going to go away as soon as soon as possible, okay,

it's going to have to wait

until this Connection Draining period is done, okay?

So this is what you need to know about this setting

at a high level.

I hope you liked it and I will see you in the next lecture.
