Okay, so now let's talk

about our lambda function configuration and performance,

and the first one I want to address is the RAM.

So currently we've been using 128 megabytes of RAM,

but we can scale up to 10 gigabytes of RAM

in one megabytes increments.

The idea is that the more RAM

or memory you add into your lambda function,

the more vCPU credits you get.

So you cannot set the number of vCPUs directly.

You have to increase the RAM to implicitly get more vCPU.

So when you reach 1,792 megabytes of RAM,

your function will have the equivalent of one full vCPU.

Afterwards, you get more than one vCPU,

and so you need to use multi-threading

to benefit from the added vCPU.

So if your application is CPU bound,

that means that it has a lot of computations,

and you want to improve the performance of your application,

that means to decrease the amount

of time your function will run for,

then you need to increase your application,

your lambda function RAM.

This is a very common exam question as well.

Then let's talk about a timeout.

So your lambda function

by default has a timeout of three seconds.

That means that if your lambda function runs

for more than three seconds,

it will error out with a timeout,

but you can set the timeout

up to a maximum of 900 seconds, which is 15 minutes.

So any interval of an execution

between 0 seconds and 15 minutes

is a good use case for lambda.

Anything above 15 minutes is not a good use case for lambda

and is something maybe that's going to be better

for Fargate, ECS, or EC2.

This is, again, something that the exam may test you on.

Next we'll talk about the performance.

So the lambda has an execution context.

It's a temporary runtime environment

that initializes any external dependencies

of your lambda code.

So you would use that context

to establish database connections,

to create your HTTP clients, or your SDK clients.

The cool thing about the execution context

is that it's maintained for some time

in anticipation of another lambda function invocation.

That means that if you invoke lambda function multiple times

in a row, then that invocation context can be reused

and reuse all these existing database connections,

GP clients and so on, and that's very helpful

because it can speed up and improve the performance

of your lambda function.

I will show you some pseudocode in a second.

Now the execution context does include the /tmp directory

that I'll be talking about in this lecture as well,

which is a space where you can write files

and they will be available across executions.

So I want to show you some code that leverages

that execution context.

So this code is bad. Why?

So we have a function called get_user_handler,

which is what lambda will be invoking.

And if you read about this code,

we get the DB_URL called os.getenv,

so we get an environment variable, and this is great.

But then the next line db_client = database.connect DB_URL.

And so while this seems correct because to get a user,

we first need to connect to the database,

every time our lambda function will be run,

this connect of the database will have to run.

So anytime someone invokes our lambda function,

it first has to connect to the database

and then get the user.

That is quite inefficient

because our lambda function may be invoked multiple times.

Instead, what AWS wants you to do, and the best practice,

is to initialize the database connection outside

of your handler, why?

Well, because it will just be initialized once,

and then it can be reused across function calls,

and it will greatly improve your function performance.

So this kind of use case is, again,

well, something that can come up at the exam,

and it will show you some pseudocode

and try to make you understand

what is good and what is bad based

on where the database connection clients

or your HTTP clients or SDK clients are opened.

Best practices, anything that takes a lot of time

to initialize, put it out of your function handler

and reuse it across executions.

Okay, lastly, what if you need to write some temporary files

and reuse them?

You can use the /tmp space.

So this is, for example,

if you need to download a big file to work

or if you need disk space to perform operations,

in this case, store all these files in a /tmp,

which means temp or temporary.

The idea is that you get 10 gigabytes of disk space

you can use for your lambda functions,

and this directory contains and remains

for the execution time of your lambda function.

So even if your lambda function stops

and then it gets reinvoked,

it is possible for you to refind the exact same files

in the /tmp space and to win a lot of time.

So this is the exact same idea with the execution context.

Here we can write very heavy files,

up to half a gigabyte, into the /tmp space.

So if you need a permanent persistence of your objects,

so non-temporary, then you need to store it in a space

that you know will be persisted across calls,

and so that space will be Amazon S3, for example.

And if you wanted to encrypt content on the /tmp space,

there is no setting to do so on lambda.

What you must do is that you must use the KMS feature

to generate data keys and actually encrypt the data

on your temp space with these data keys.

So we have seen all the ways we can improve the performance

of our lambda functions.

Now let's go into the console to play with those.

So for this hands-on, let's go

into the lambda-config-demo and we're going to have a look

at the different options that impact our Lambda function.

So if we go into the configuration, our Lambda function,

the first thing we see is that under general configuration

we can edit the basic settings.

So we've seen them before, but now let's have a look again,

so the memory can be anywhere between one and 28 gigabytes

to 10,240 megabytes in total, and so the more memory we add,

the more CPU we're going to have.

So as you can see here,

we can have as much memory as we want, okay.

And the CPU is proportionally located to the memory.

And the idea is that if you have maybe 10,200,

so the maximum amount of memory,

then you're going to pay a lot more

for your Lambda function then if you had the minimum.

So the idea for you is

to really monitor the Lambda function memory usage,

and make sure you set your memory accordingly

so that you have enough memory to perform what you need

but not too much so that you don't get over billed.

And the very popular exam question is

that if you need a faster CPU or more CPU cores

for your Lambda function, the setting

to do it is by modifying the memory.

There is no way to change the CPU independently

from the memory in your Lambda function today.

Okay, in terms of timeout,

this is how long your Lambda function will run

before throwing an error and run out.

It's set to three seconds

and we're going to have a play with it in a second,

so let's leave the timeout to three seconds

and let's have a Lambda function do some work.

So let's keep this in the function,

and I'm going to import the time library at the very top,

and then we're going to time.sleep2

and this is to simulate some work.

So by sleeping the Lambda function for two seconds,

we are saying that the Lambda function does some work

and after two seconds it's going to return the results.

So let's deploy this and test this.

As we can see, after two seconds we get the response prod,

so the duration was 2000 milliseconds, approximately.

But what happens if we make the Lambda function

sleep five seconds?

So now the Lambda function is doing a lot of work,

maybe more than what we expected from before.

So let's deploy the changes and click on test.

Now what's going to happen is

that the Lambda function will fail.

Why? Because it will timeout.

So we got an error message here saying,

Hey the tasks timed out after three seconds and this is

because, well under the configuration tabs,

our Lambda function right here, we did decide

for the timeout to be three seconds.

But now if we change the timeout to be six seconds, okay,

because we know that our Lambda function is doing more work

than expected and then we test our Lambda function again.

Well, this time the execution results should be successful

after five seconds because we don't hit the timeout,

and then yes, we get the response properly

and the duration is 5,000 milliseconds.

So we really see the impact of timeout

on the function itself.

And so something you may ask me is, "Hey, Stefan,

why don't we just always set the timeout to

be something very large, like the 15 minutes or 10 minutes?"

Well, if you do so and imagine your Lambda function

gets stuck and you know that on average Lambda function

takes no more than 10 seconds to execute,

then you may not go fast enough into an error case

and therefore, maybe you retry something

or get your function unstuck.

So it's up to you to set a timeout

to something that you think is reasonable for a function

because you want it to fail when something

within your function goes wrong and analyze that error case,

instead of just waiting 15 minutes for your function

to timeout and maybe get an error, so it's up to you.

It depends on use case and what your function does

but set the timeout accordingly.

Last thing to optimize your Lambda function performance

is around where you set the initialization of your function.

So if you're connecting to a DB, connect to DB function.

You want it to have outside of your function handler.

Well, let's say for example that you put it inside,

okay, and that your function connect to DB

right now does time.sleep3

Okay, so connecting to the DB takes about three seconds.

If we have this function right here

where we connect to the database within the Lambda handler,

that means that every time we invoke our function

this function connects to DB is going to be run it's going

to take three seconds because it takes a long time

to connect your database and then is going

to return the results you have.

So if we test it, this is going to take 3 seconds.

So we wait,, one, two, and three.

Okay, great.

We want to run it again.

So one, two, and three.

So as you can see, every time we run our function,

it lasts three seconds because we are connecting

to database every single time, okay?

But the optimization that we saw

and something the exam will ask you is that instead

of doing the connection to the database

within the Lambda handler, you do it outside of it.

So let's deploy this and see the difference.

So now we connect to the database

before doing the Lambda handler.

So we'll test it, one, two, three, this takes a lot of time

and this is not working because we need to....

Yes, so if you go to the results it says that connect

to DB is not defined so I need to define my function connect

to DB before invoking it.

That makes a lot of sense.

So let's just move this function definition up.

So we're going to deploy the changes, test again.

So one, two, three

and this is how long it takes for my function to initialize.

So as we can see here,

the duration of the function was one millisecond

but the INET duration was 3000 millisecond,

so this is the time it took

for my function to run the very, very first time.

But now if I test my function again,

it takes less than one millisecond

because this part of the code is not run again.

So we can test, test, test,

and now my function is much quicker

because we've done the database initialization again

outside of the function handler.

So hopefully this is a good demo.

Imagine that instead of here, instead of sleeping,

you actually connect to the database

and you get a database object out of it

that you can use within your Lambda handler.

So that's it for this lecture.

I hope you liked it,

and I will see you in the next lecture.

