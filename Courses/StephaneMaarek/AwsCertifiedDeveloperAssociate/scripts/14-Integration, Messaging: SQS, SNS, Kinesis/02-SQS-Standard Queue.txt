So let's about SQS,

and at the core of SQS is a queue

because SQS is a simple queuing service.

So we have an SQS queue,

and it is going to contain messages.

And to contain messages,

well, something needs to send messages into our SQS queue

and whatever sends a message into our SQS queue

is called a producer.

So it's possible for us to have one producer,

but also have more.

You can have multiple producers

sending many messages into an SQS queue.

And the message could be whatever he wants.

For example, it could be process this order,

or process this video.

Whatever message you create goes into the queue.

Then something needs to process the messages from the queue

and receive them, and it's called consumers.

So consumers will poll the messages from the queue,

so that means that they will ask the queue,

do you have any message for me?

And the queue says, yes, here it is.

And the consumer will poll these messages

and get some information.

And then with that message,

it will process it and then delete it back from the queue.

And you may have multiple consumers

consuming messages from an SQS queue.

So a queuing service is here to be a buffer

to decouple between your producers and your consumers.

Now, SQS is a complicated service

and we'll see that in-depth,

but the very first offering is called Amazon SQS

for standard queues.

And SQS, historically on AWS, it is the oldest offering.

It was one of the first services on AWS.

It's over 10 years old so it's quite,

quite set in stone about how it works.

It's a fully managed service,

and it will be used to decouple applications.

So anytime you see application decoupling in your exam,

think about Amazon SQS.

Now, why is SQS so special?

Well, we get an unlimited throughputs.

That means you can send

as many messages per second as you want,

and the queue can have as many messages as you want as well.

So there's no limit on throughputs

and no limits in the number of messages in the queue.

Now, each message is short-lived.

What does that mean?

That means that by default,

the message will stay in the queue for four days

and the maximum amount of time

that a message can be in a queue is 14 days.

That means that as soon as you send a message to a queue,

it has to be read by consumer and deleted from the queue

after being processed within that retention period,

otherwise, it will be lost.

Then we have low-latency.

So SQS means that, for them,

is that whenever you send a message

or read a message from SQS,

you will get a response very quickly,

less than 10 milliseconds on publish and receive.

And the messages in SQS have to be small.

They have to be less than 256 kilobytes per messages sent.

Now SQS is a queuing service,

so you can see high throughput, high volume, and so on,

and so, it is possible to have duplicates messages.

That means that, for example,

sometimes a message will be delivered twice,

and so this is why it's called at least once delivery.

And if you go ahead with writing an application,

you need to take that into account.

It can also have out of the order messages,

which means it's best effort ordering,

and we'll see there is another type of offering from SQS

that can deal with that limitation,

but we'll see this later on in this section.

So, let's go back to our message producers.

So, messages that are up to 256 kilobytes

are sent into SQS by producers.

And how does it happen?

Well, the producers will send the messages to SQS

using an SDK, software development kits.

And the API to send a message to SQS is called SendMessage.

Very simple.

Now the message, it will be written,

it will be persisted into the SQS queue

until a consumer reads that message and deletes it,

which signifies that the message has been processed.

We know the retention.

And so, what's a use case for producing messages?

For example, you want to process an order,

for example, packets, and then ship it to the center.

And so you wanna do this in your own time

so you will send a message into the SQS queue

with maybe some information,

such as the order ID, the customer ID,

and any attributes you may want.

For example, the address, and so on.

And then your consumer, that is in application rights,

will have to deal with that message itself.

So, again, to confirm,

SQS standard has unlimited throughputs.

So we've seen about producers. Very simple.

Now let's look about consumers.

So consumers, they are applications

that we have to write with some code

and these applications can be running on EC2 instances,

so your virtual servers on AWS,

but also they can be running on your own on-premises servers

if you wanted to,

or, we haven't seen it yet,

but they can also be running

on Lambda functions on AWS Lambda.

We'll see in this course,

it is a serverless compute type of service.

What this means is that you can just read messages

directly from them as well.

We'll see this later on this course, do not worry.

So, going back to our simple use case about EC2 instances,

our queue has a consumer

and the consumer polls for SQS for messages.

And that means that the consumer will ask the queue,

do you have messages for me?

And the consumer may receive up to 10 messages at a time.

So if there are messages in the SQS queue,

it will receive a valid response saying

here are the messages that are waiting for you.

Then the consumer, it's your code,

has a responsibility to process these messages.

For example, insert some orders into an RDS database.

So you will go ahead and for each order,

you will insert it into your RDS database,

something that you have to write, obviously with your code,

and then because these messages have been processed

because they have been received

and inserted into an Amazon RDS database,

your consumer will go ahead

and delete these messages from the queue

using the DeleteMessage API.

And this will guarantee that no other consumer

will be able to see these messages

and therefore, the message processing is complete.

So now we can scale this up.

We can have multiple consumers at a time.

So our SQS queue can have multiple consumers

that will receive and process these messages in parallel.

So here we have three on EC2 instances,

and so each consumer will receive

a different set of messages by calling the poll function.

And so, if somehow a message

is not processed fast enough by a consumer,

it will be received by other consumers,

and so this is why we have at least once delivery.

And this is also why we have best-effort message ordering.

Now, as I said, when the consumers

are done with the messages, they will have to delete them,

otherwise, other consumers will see these messages.

And so what this means is that with SQS queues,

if we need to increase the throughputs

because we have more messages,

then we can add consumers and do horizontal scaling

to improve the throughput of processing.

And so, if you remember what we said,

this is a perfect use case for using SQS

with your Auto Scaling groups, or ASG.

So, what does that mean?

Well, that means that your consumers

will be running on EC2 instances

inside of an Auto Scaling group

and they will be polling for messages from the SQS queue.

But now your Auto Scaling group has to be scaling

on some kind of metric,

and a metric that is available to us is the Queue Length.

It's called ApproximateNumberOfMessages.

It is a CloudWatch Metric that's available in any SQS queue.

And we could set up an alarm,

such as whenever the queue length go over a certain level,

then please set up a CloudWatch Alarm,

and this alarm should increase the capacity

of my Auto Scaling group by X amount.

And this will guarantee that

the more messages you have in your SQS queue,

maybe because there's a surge of orders on your websites,

the more EC2 instances will be provided

by your Auto Scaling group,

and you will accordingly process these messages

at a higher throughputs.

So this is a very common integration

that you will see in the exam.

Now SQS, again, the use case

is to decouple between applications, so application tiers.

So, for example, let's take an example of an application

that processes videos.

We could have just one big application

that's called a front-end that will take the request

and whenever a video needs to be processed,

it will do the processing

and then insert that into an S3 bucket.

But the problem is that processing

may be very, very long to do

and it may just slow down your websites

if you do this in the front-end here.

So instead, you can decouple your application here and say,

wait a minute, the request of processing a file

and the actual processing of a file

can happen in two different applications.

And therefore, whenever you take a request

to process a file,

you will send a message into an SQS queue.

Now, when you do the request to process,

that file will be in the SQS queue

and you can create a second processing tier

called the back-end processing application

that will be in its own Auto-Scaling group

to receive these messages, process these videos,

and insert them into an S3 bucket.

So as we can see here with this architecture,

we can scale the front-end accordingly,

and we can scale the back-end accordingly as well,

but independently.

And because the SQS queue has unlimited throughputs

and it has unlimited number of messages

in terms of the queue, then you are really safe,

and this is a robust and scalable type of architecture.

And also, for your front-end,

you can use the optimal type of EC2 instances

or architecture for your front-end.

And for the back-end,

maybe if you're doing some video processing,

you can use some EC2 instances

that have a GPU, a graphical processing unit,

because you know that these type of instances

will be optimal for doing this kind of workload.

So this is the kind of architecture

that will come up in the exam

and that you're expected to know,

and this is an amazing and tremendous use case

for SQS queues.

Finally, SQS security.

So we have encryption in-flight

by sending and producing messages using the HTTPS API,

we get at-rest encryption using KMS keys,

and if we wanted to, we can do client-side encryption,

but that means that the client has to perform

the encryption and the decryption itself.

It's not something that's supported by SQS out of the box.

For access controls, IAM policies are going to be able to

regulate access to the SQS API,

but we also have SQS access policies,

which are similar to S3 bucket policies,

and they're very helpful when you want to do

cross-account access to SQS queue,

or when you want you to allow other services,

such as SNS that we'll see very soon, or Amazon S3,

to write to an SQS queue,

for example, with S3 events.

So that's it for SQS for an overview.

I hope you liked it,

and I will see you in the next lecture for some practice.

# Hands On.

So, let's practice Amazon SQS.

So we are going to go into the SQS console

and then create a queue.

Now as we can see, we have two types of queue

we can set up in SQS.

We have the standard queue and the FIFO queue.

And I'm going to use standard

and the name is going to be Demo Queue.

We'll see FIFO later on.

For configuration, all these things we're going to see

in future lectures

so visibility timeout, delivery delay, the wait time,

the retention period, we're going to use four days

and the max message size is going to be 256 kilobytes

which is a max allowed in SQS.

For encryption, we have several encryption options

so we can disable encryption for our queue altogether

but by default we enable it with an Amazon SQS key.

It's called SSE-SQS type of encryption

which is similar to what we have in Amazon S3 with SSE-S3.

So that's one option for server side encryption.

The other one is to use KMS.

And this is where we have to choose the customer master key.

So we can choose the default CMK of AWS

called the alias/AWS/SQS

and then we can define a data key reuse period

that could be five minutes, for example.

This is to limit the number of API calls made in two KMS.

But this is not very important

so let's keep the encryption as Amazon SQS key,

SSE-SQS.

All right.

Next we have an access policy.

And this access policy can be defined

using these prompts right here.

So we can say, 'Hey, who can access this queue well?'

Only the queue owner can send messages

or maybe I wanna specify a list of accounts,

users and roles and then who can receive, again.

Is it just me, the queue owner

or specified accounts, users and roles?

And this will generate a json document out of it

and this json document, as you can see,

looks very similar to what we had in Amazon S3

with Amazon S3 Bucket policy.

So this is a resource policy for SQS

and it works very very similarly.

Now for the redrive and the dead-letter queue,

we'll see this later on so right now, we're good.

Let's go ahead and create our queue.

And now the queue is successfully created

so we can go ahead and send and receive messages from it.

So we get a lot of different panels in this UI

but what we want to be doing is

to go to the top right-hand side

and click on send and receive messages.

So here is a facility for us to send messages

and then at the bottom, to receive them.

So as we can see right now in the queue,

we have zero messages available.

But if I enter 'hello world!' in the message body

and then send the message.

As you can see, the message is sent

and is ready to be received.

Now we have a messages available one,

and so in here, as soon as I click on pull for messages,

the messages will appear.

So let's have a look.

I click on pull for messages

and yes, we did receive that message right here.

As we can see, we have a message id.

And if you want to look at the content of the message,

I click on the message details

and I can have some information.

So there's a lot of metadata around that message.

For example, the hash of the message, who sent it,

how many times were received so just one time right now

because this is the first time we process this message,

the size in bytes.

And if we go and want to receive the body itself,

we can see that whatever has sent before 'hello world!'

has in it up right here in the message that has just read.

If we created attributes for the message,

there was a message attributes panel that we didn't look at,

we could create key values and read them from here as well.

So very simple, what you would expect

when you send a message and then read it,

you get the exact same message.

But we have decoupled

because a producer has sent some information

and a consumer has received that information.

Now we can see that the message has been received twice

because we didn't process it in enough time.

So after 30 seconds, the message went back into the queue

and we received it again.

So if I pull for messages,

now the message receive count is three.

So it has been read yet again another time.

So to be done with this message,

because say we've processed this 'hello world!' Message,

I'm going to click on it

and then I'm going to click on delete.

And by deleting the message from the queue,

we have signaled to the SQS queue

that the message has been successfully processed

and therefore we have zero messages available in the queue.

And if we pull again,

we will not receive the same message again

because we have deleted it.

So you start seeing the power of queues.

We could go ahead and send many times different messages,

hello world and so on, and you can just play with it

and this is how you would set message attributes

but this is out of scope for the exam.

And here you would receive these messages

and you can receive many messages at time.

So if we send 'hello world', we'll send that message again

and 'hello world 2' for example and send that message

and 'hello world 3',

whatever you want really in that message.

As we can see, as soon as I refresh this window,

we can see that the number of messages available is three.

And so if I pull for messages,

I will get three messages available in here to be processed.

And again, you can take them all

and delete them to signal to SQS

that they have been processed.

So fairly easy.

But you've seen the power of producers and consumers.

Now, back in the queue,

just a few options as well we can see out.

So we can edit this queue to edit all the configurations

that we've seen from before or you can purge the queue.

This will delete all the messages in the queue.

And so to delete all the messages,

you just need to type purge,

and it will go ahead and remove everything

which is very helpful when you do developments.

But I don't think you should do this in production.

And then you get some information around monitoring

for example here, which gives you some information around

how many messages are in the queue,

what's the approximate age of the oldest message,

which could be another way to scale your SQS Queue

if you have an auto-scaling group reading from it,

and so on.

And finally, access policy,

which is who can access the queue and how;

encryption, which is the service side encryption we defined

for our SQS queue.

So for example, we're using SSE-SQS right now

as our encryption scheme, but we can edit it.

And finally, the dead-letter redrive status

which is relevant if you set up a dead letter queue.

So that's it for this lecture.

I hope you liked it, and I will see you in the next lecture.